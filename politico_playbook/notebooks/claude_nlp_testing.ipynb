{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude NLP Processor Testing Notebook\n",
    "\n",
    "This notebook demonstrates and tests the Claude NLP processor on different types of Politico newsletters. It showcases the system's ability to extract comprehensive political intelligence across various newsletter formats and content types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment loaded\n",
      "📁 Data directory: data/structured\n",
      "💾 Output directory: data/claude_enhanced\n",
      "🔑 API key configured: Yes\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import our Claude NLP processor\n",
    "from src.processing.claude_nlp_processor import ClaudeNLPProcessor\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path(\"data/structured\")\n",
    "OUTPUT_DIR = Path(\"data/claude_enhanced\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"✅ Environment loaded\")\n",
    "print(f\"📁 Data directory: {DATA_DIR}\")\n",
    "print(f\"💾 Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"🔑 API key configured: {'Yes' if os.getenv('ANTHROPIC_API_KEY') else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Claude NLP Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Claude NLP Processor initialized\n",
      "📊 Primary model: claude-3-5-haiku-20241022\n",
      "🧠 Escalation model: claude-3-5-sonnet-20241022\n",
      "🎯 Confidence threshold: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the processor\n",
    "processor = ClaudeNLPProcessor()\n",
    "\n",
    "print(f\"🤖 Claude NLP Processor initialized\")\n",
    "print(f\"📊 Primary model: {processor.haiku_model}\")\n",
    "print(f\"🧠 Escalation model: {processor.sonnet_model}\")\n",
    "print(f\"🎯 Confidence threshold: {processor.confidence_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newsletter Discovery and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📰 Found 20 newsletters\n",
      "\n",
      "📊 Newsletter Types:\n",
      "  new_york_playbook: 2 newsletters\n",
      "  national_playbook: 5 newsletters\n",
      "  florida_playbook: 1 newsletters\n",
      "  california_playbook: 1 newsletters\n",
      "  politico_pulse: 1 newsletters\n",
      "\n",
      "📈 Newsletter Overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-02_151600_email.json</td>\n",
       "      <td>new_york_playbook</td>\n",
       "      <td>The fraudster behind California secession</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>7564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-01_105927_email.json</td>\n",
       "      <td>national_playbook</td>\n",
       "      <td>A tale of two swing districts</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>16790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-01_112515_email.json</td>\n",
       "      <td>national_playbook</td>\n",
       "      <td>Pressley’s message from Meixco</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>12803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-01_174530_email.json</td>\n",
       "      <td>national_playbook</td>\n",
       "      <td>A wobbly jobs report shakes Trump’s economy</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>16838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-01_110122_email.json</td>\n",
       "      <td>florida_playbook</td>\n",
       "      <td>Republicans’ summer shindig</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>13346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file               type  \\\n",
       "0  2025-08-02_151600_email.json  new_york_playbook   \n",
       "1  2025-08-01_105927_email.json  national_playbook   \n",
       "2  2025-08-01_112515_email.json  national_playbook   \n",
       "3  2025-08-01_174530_email.json  national_playbook   \n",
       "4  2025-08-01_110122_email.json   florida_playbook   \n",
       "\n",
       "                                       subject        date  text_length  \n",
       "0    The fraudster behind California secession  2025-08-02         7564  \n",
       "1                A tale of two swing districts  2025-08-01        16790  \n",
       "2               Pressley’s message from Meixco  2025-08-01        12803  \n",
       "3  A wobbly jobs report shakes Trump’s economy  2025-08-01        16838  \n",
       "4                  Republicans’ summer shindig  2025-08-01        13346  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Discover available newsletters\n",
    "newsletter_files = list(DATA_DIR.glob(\"*.json\"))\n",
    "\n",
    "print(f\"📰 Found {len(newsletter_files)} newsletters\")\n",
    "\n",
    "# Load and classify newsletters by type\n",
    "newsletters_by_type = {}\n",
    "all_newsletters = []\n",
    "\n",
    "for file_path in newsletter_files[:10]:  # Limit for demo\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            newsletter = json.load(f)\n",
    "            \n",
    "        playbook_type = newsletter.get('playbook_type', 'unknown')\n",
    "        subject = newsletter.get('subject_line', 'No subject')\n",
    "        date = newsletter.get('date', 'Unknown date')\n",
    "        text_length = len(newsletter.get('text', ''))\n",
    "        \n",
    "        newsletter_info = {\n",
    "            'file': file_path.name,\n",
    "            'type': playbook_type,\n",
    "            'subject': subject[:80] + '...' if len(subject) > 80 else subject,\n",
    "            'date': date,\n",
    "            'text_length': text_length,\n",
    "            'data': newsletter\n",
    "        }\n",
    "        \n",
    "        all_newsletters.append(newsletter_info)\n",
    "        \n",
    "        if playbook_type not in newsletters_by_type:\n",
    "            newsletters_by_type[playbook_type] = []\n",
    "        newsletters_by_type[playbook_type].append(newsletter_info)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error loading {file_path.name}: {e}\")\n",
    "\n",
    "# Display newsletter types and counts\n",
    "print(\"\\n📊 Newsletter Types:\")\n",
    "for newsletter_type, newsletters in newsletters_by_type.items():\n",
    "    print(f\"  {newsletter_type}: {len(newsletters)} newsletters\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "df_newsletters = pd.DataFrame([\n",
    "    {\n",
    "        'file': n['file'],\n",
    "        'type': n['type'],\n",
    "        'subject': n['subject'],\n",
    "        'date': n['date'],\n",
    "        'text_length': n['text_length']\n",
    "    } for n in all_newsletters\n",
    "])\n",
    "\n",
    "print(\"\\n📈 Newsletter Overview:\")\n",
    "display(df_newsletters.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Processing on Different Newsletter Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Sample from Each Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Selected 5 newsletters for testing:\n",
      "  📰 new_york_playbook: It’s down to Trump, Schumer and Thune (12,158 chars)\n",
      "  📰 national_playbook: The new master of the Senate (24,552 chars)\n",
      "  📰 florida_playbook: Republicans’ summer shindig (13,346 chars)\n",
      "  📰 california_playbook: Cash flows to Porter and dries up for Kounalakis (14,586 chars)\n",
      "  📰 politico_pulse: Trump’s top brass turnover hits HHS (11,876 chars)\n"
     ]
    }
   ],
   "source": [
    "# Select one newsletter from each type for detailed analysis\n",
    "test_newsletters = []\n",
    "for newsletter_type, newsletters in newsletters_by_type.items():\n",
    "    if newsletters:\n",
    "        # Pick the newsletter with the most content\n",
    "        best_newsletter = max(newsletters, key=lambda x: x['text_length'])\n",
    "        test_newsletters.append(best_newsletter)\n",
    "\n",
    "print(f\"🧪 Selected {len(test_newsletters)} newsletters for testing:\")\n",
    "for newsletter in test_newsletters:\n",
    "    print(f\"  📰 {newsletter['type']}: {newsletter['subject']} ({newsletter['text_length']:,} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Newsletters with Claude NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Processing single newsletter: new_york_playbook\n",
      "📄 Subject: It’s down to Trump, Schumer and Thune\n",
      "Processing newsletter: It’s down to Trump, Schumer and Thune\n",
      "Warning: No JSON found in Claude response\n",
      "  → Escalating to Sonnet for enhanced accuracy\n",
      "  ⚠️  Warning: Only 3 people extracted. Typical newsletters have 15-30+ people.\n",
      "     This may indicate overly conservative extraction. Consider reviewing the results.\n",
      "✅ Success: 3 people, 1 relationships, 0 organizations, 2 stories\n",
      "⏱️  Processing time: 19.4s\n",
      "🎯 Confidence: 0.95\n",
      "🚀 Escalated: Yes\n"
     ]
    }
   ],
   "source": [
    "# Process only the first newsletter in test_newsletters with Claude NLP\n",
    "single_newsletter = test_newsletters[0]\n",
    "print(f\"🔄 Processing single newsletter: {single_newsletter['type']}\")\n",
    "print(f\"📄 Subject: {single_newsletter['subject']}\")\n",
    "\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    enhanced_data = processor.process_newsletter(single_newsletter['data'].copy())\n",
    "    processing_time = (datetime.now() - start_time).total_seconds()\n",
    "    claude_results = enhanced_data.get('claude_nlp_results', {})\n",
    "    processing_info = claude_results.get('processing_info', {})\n",
    "    people_count = len(claude_results.get('people', []))\n",
    "    relationships_count = len(claude_results.get('relationships', []))\n",
    "    organizations_count = len(claude_results.get('organizations', []))\n",
    "    stories_count = len(claude_results.get('stories_and_topics', []))\n",
    "    print(f\"✅ Success: {people_count} people, {relationships_count} relationships, {organizations_count} organizations, {stories_count} stories\")\n",
    "    print(f\"⏱️  Processing time: {processing_time:.1f}s\")\n",
    "    print(f\"🎯 Confidence: {processing_info.get('confidence_score', 0):.2f}\")\n",
    "    print(f\"🚀 Escalated: {'Yes' if processing_info.get('escalated') else 'No'}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error processing newsletter: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each test newsletter\n",
    "processing_results = []\n",
    "\n",
    "for i, newsletter_info in enumerate(test_newsletters):\n",
    "    print(f\"\\n🔄 Processing {i+1}/{len(test_newsletters)}: {newsletter_info['type']}\")\n",
    "    print(f\"📄 Subject: {newsletter_info['subject']}\")\n",
    "    \n",
    "    try:\n",
    "        # Process with Claude\n",
    "        start_time = datetime.now()\n",
    "        enhanced_data = processor.process_newsletter(newsletter_info['data'].copy())\n",
    "        processing_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # Extract results\n",
    "        claude_results = enhanced_data.get('claude_nlp_results', {})\n",
    "        processing_info = claude_results.get('processing_info', {})\n",
    "        \n",
    "        # Count entities\n",
    "        people_count = len(claude_results.get('people', []))\n",
    "        relationships_count = len(claude_results.get('relationships', []))\n",
    "        organizations_count = len(claude_results.get('organizations', []))\n",
    "        stories_count = len(claude_results.get('stories_and_topics', []))\n",
    "        \n",
    "        # Analyze people by category\n",
    "        people = claude_results.get('people', [])\n",
    "        political_officials = [p for p in people if p.get('category') == 'political_official']\n",
    "        journalists = [p for p in people if p.get('category') == 'journalist']\n",
    "        staff = [p for p in people if p.get('category') in ['staff', 'political_staff']]\n",
    "        \n",
    "        result_summary = {\n",
    "            'newsletter_type': newsletter_info['type'],\n",
    "            'subject': newsletter_info['subject'],\n",
    "            'processing_time': processing_time,\n",
    "            'escalated': processing_info.get('escalated', False),\n",
    "            'confidence_score': processing_info.get('confidence_score', 0),\n",
    "            'people_total': people_count,\n",
    "            'political_officials': len(political_officials),\n",
    "            'journalists': len(journalists),\n",
    "            'staff': len(staff),\n",
    "            'relationships': relationships_count,\n",
    "            'organizations': organizations_count,\n",
    "            'stories': stories_count,\n",
    "            'enhanced_data': enhanced_data,\n",
    "            'claude_results': claude_results\n",
    "        }\n",
    "        \n",
    "        processing_results.append(result_summary)\n",
    "        \n",
    "        print(f\"✅ Success: {people_count} people, {relationships_count} relationships\")\n",
    "        print(f\"⏱️  Processing time: {processing_time:.1f}s\")\n",
    "        print(f\"🎯 Confidence: {processing_info.get('confidence_score', 0):.2f}\")\n",
    "        print(f\"🚀 Escalated: {'Yes' if processing_info.get('escalated') else 'No'}\")\n",
    "        \n",
    "        # Save enhanced results\n",
    "        output_file = OUTPUT_DIR / f\"claude_test_{newsletter_info['file']}\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(enhanced_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"💾 Saved to: {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {newsletter_info['type']}: {e}\")\n",
    "        result_summary = {\n",
    "            'newsletter_type': newsletter_info['type'],\n",
    "            'subject': newsletter_info['subject'],\n",
    "            'error': str(e)\n",
    "        }\n",
    "        processing_results.append(result_summary)\n",
    "\n",
    "print(f\"\\n🏁 Processing complete: {len(processing_results)} newsletters processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary DataFrame\n",
    "successful_results = [r for r in processing_results if 'error' not in r]\n",
    "\n",
    "if successful_results:\n",
    "    df_results = pd.DataFrame(successful_results)\n",
    "    \n",
    "    print(\"📊 Processing Performance Summary:\")\n",
    "    print(f\"  Total newsletters processed: {len(successful_results)}\")\n",
    "    print(f\"  Average processing time: {df_results['processing_time'].mean():.1f}s\")\n",
    "    print(f\"  Escalation rate: {df_results['escalated'].mean()*100:.1f}%\")\n",
    "    print(f\"  Average confidence: {df_results['confidence_score'].mean():.2f}\")\n",
    "    print(f\"  Average entities per newsletter: {df_results['people_total'].mean():.1f}\")\n",
    "    \n",
    "    # Display detailed results table\n",
    "    display_columns = ['newsletter_type', 'processing_time', 'escalated', 'confidence_score', \n",
    "                      'people_total', 'political_officials', 'journalists', 'staff', \n",
    "                      'relationships', 'organizations']\n",
    "    \n",
    "    print(\"\\n📋 Detailed Results:\")\n",
    "    display(df_results[display_columns])\n",
    "else:\n",
    "    print(\"⚠️  No successful processing results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Extraction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if successful_results:\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Entity counts by newsletter type\n",
    "    entity_data = df_results.set_index('newsletter_type')[['political_officials', 'journalists', 'staff']]\n",
    "    entity_data.plot(kind='bar', ax=axes[0,0], title='Entity Counts by Newsletter Type')\n",
    "    axes[0,0].set_ylabel('Number of Entities')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Processing time vs escalation\n",
    "    colors = ['red' if escalated else 'blue' for escalated in df_results['escalated']]\n",
    "    axes[0,1].scatter(df_results['confidence_score'], df_results['processing_time'], c=colors, alpha=0.7)\n",
    "    axes[0,1].set_xlabel('Confidence Score')\n",
    "    axes[0,1].set_ylabel('Processing Time (seconds)')\n",
    "    axes[0,1].set_title('Processing Time vs Confidence (Red = Escalated)')\n",
    "    \n",
    "    # 3. Total entities vs relationships\n",
    "    axes[1,0].scatter(df_results['people_total'], df_results['relationships'], alpha=0.7)\n",
    "    axes[1,0].set_xlabel('Total People')\n",
    "    axes[1,0].set_ylabel('Relationships')\n",
    "    axes[1,0].set_title('People vs Relationships Extracted')\n",
    "    \n",
    "    # 4. Entity type distribution\n",
    "    entity_totals = {\n",
    "        'Political Officials': df_results['political_officials'].sum(),\n",
    "        'Journalists': df_results['journalists'].sum(),\n",
    "        'Staff': df_results['staff'].sum()\n",
    "    }\n",
    "    axes[1,1].pie(entity_totals.values(), labels=entity_totals.keys(), autopct='%1.1f%%')\n",
    "    axes[1,1].set_title('Overall Entity Type Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️  No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Entity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Entity Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed results for each newsletter type\n",
    "for result in successful_results:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"📰 Newsletter Type: {result['newsletter_type']}\")\n",
    "    print(f\"📄 Subject: {result['subject']}\")\n",
    "    print(f\"⏱️  Processing: {result['processing_time']:.1f}s ({'Escalated' if result['escalated'] else 'Primary only'})\")\n",
    "    print(f\"🎯 Confidence: {result['confidence_score']:.2f}\")\n",
    "    \n",
    "    claude_results = result['claude_results']\n",
    "    people = claude_results.get('people', [])\n",
    "    \n",
    "    # Show top political officials\n",
    "    political_officials = [p for p in people if p.get('category') == 'political_official']\n",
    "    if political_officials:\n",
    "        print(f\"\\n🏛️  Political Officials ({len(political_officials)}):\")\n",
    "        for person in political_officials[:5]:  # Show top 5\n",
    "            role = person.get('role', 'Unknown')\n",
    "            party = person.get('party', '')\n",
    "            party_str = f\" ({party})\" if party else \"\"\n",
    "            activity = person.get('activity', 'No activity specified')[:100]\n",
    "            print(f\"  • {person['name']} - {role}{party_str}\")\n",
    "            print(f\"    Activity: {activity}\")\n",
    "    \n",
    "    # Show journalists\n",
    "    journalists = [p for p in people if p.get('category') == 'journalist']\n",
    "    if journalists:\n",
    "        print(f\"\\n📰 Journalists ({len(journalists)}):\")\n",
    "        for person in journalists[:3]:  # Show top 3\n",
    "            employer = person.get('employer', 'Unknown')\n",
    "            reported_on = person.get('reported_on', [])\n",
    "            reported_str = ', '.join(reported_on[:2]) if reported_on else 'General reporting'\n",
    "            print(f\"  • {person['name']} ({employer})\")\n",
    "            print(f\"    Reported on: {reported_str}\")\n",
    "    \n",
    "    # Show key relationships\n",
    "    relationships = claude_results.get('relationships', [])\n",
    "    if relationships:\n",
    "        print(f\"\\n🤝 Key Relationships ({len(relationships)}):\")\n",
    "        for rel in relationships[:3]:  # Show top 3\n",
    "            predicate = rel.get('predicate', 'interacted with').replace('_', ' ')\n",
    "            print(f\"  • {rel['subject']} {predicate} {rel['object']}\")\n",
    "            if 'context' in rel:\n",
    "                context = rel['context'][:80] + '...' if len(rel['context']) > 80 else rel['context']\n",
    "                print(f\"    Context: {context}\")\n",
    "    \n",
    "    # Show stories/topics\n",
    "    stories = claude_results.get('stories_and_topics', [])\n",
    "    if stories:\n",
    "        print(f\"\\n📈 Key Stories ({len(stories)}):\")\n",
    "        for story in stories[:2]:  # Show top 2\n",
    "            topic = story.get('topic', 'Unknown topic')\n",
    "            details = story.get('details', 'No details')[:100]\n",
    "            print(f\"  • {topic}\")\n",
    "            print(f\"    {details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newsletter Type Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if successful_results:\n",
    "    # Compare characteristics across newsletter types\n",
    "    comparison_data = []\n",
    "    \n",
    "    for result in successful_results:\n",
    "        newsletter_type = result['newsletter_type']\n",
    "        people = result['claude_results'].get('people', [])\n",
    "        \n",
    "        # Analyze political focus\n",
    "        federal_officials = len([p for p in people if p.get('role', '').lower() in \n",
    "                               ['president', 'senator', 'representative', 'secretary', 'majority leader', 'minority leader']])\n",
    "        state_officials = len([p for p in people if p.get('role', '').lower() in \n",
    "                             ['governor', 'state senator', 'state representative', 'mayor']])\n",
    "        \n",
    "        # Analyze party distribution\n",
    "        republicans = len([p for p in people if p.get('party', '').lower() == 'republican'])\n",
    "        democrats = len([p for p in people if p.get('party', '').lower() == 'democrat'])\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'type': newsletter_type,\n",
    "            'total_people': len(people),\n",
    "            'federal_officials': federal_officials,\n",
    "            'state_officials': state_officials,\n",
    "            'republicans': republicans,\n",
    "            'democrats': democrats,\n",
    "            'journalists': result['journalists'],\n",
    "            'staff': result['staff']\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"🔍 Newsletter Type Characteristics:\")\n",
    "    display(df_comparison)\n",
    "    \n",
    "    # Visualize the comparison\n",
    "    if len(df_comparison) > 1:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Official types by newsletter\n",
    "        df_comparison.set_index('type')[['federal_officials', 'state_officials']].plot(\n",
    "            kind='bar', ax=ax1, title='Federal vs State Officials by Newsletter Type'\n",
    "        )\n",
    "        ax1.set_ylabel('Number of Officials')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Party distribution\n",
    "        df_comparison.set_index('type')[['republicans', 'democrats']].plot(\n",
    "            kind='bar', ax=ax2, title='Party Distribution by Newsletter Type', color=['red', 'blue']\n",
    "        )\n",
    "        ax2.set_ylabel('Number of People')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Assessment and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if successful_results:\n",
    "    print(\"📊 CLAUDE NLP PROCESSOR ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Calculate aggregate metrics\n",
    "    total_newsletters = len(successful_results)\n",
    "    avg_processing_time = df_results['processing_time'].mean()\n",
    "    escalation_rate = df_results['escalated'].mean() * 100\n",
    "    avg_confidence = df_results['confidence_score'].mean()\n",
    "    total_entities = df_results['people_total'].sum()\n",
    "    avg_entities_per_newsletter = df_results['people_total'].mean()\n",
    "    \n",
    "    print(f\"\\n🔢 Processing Statistics:\")\n",
    "    print(f\"  Newsletters processed: {total_newsletters}\")\n",
    "    print(f\"  Average processing time: {avg_processing_time:.1f} seconds\")\n",
    "    print(f\"  Escalation rate: {escalation_rate:.1f}%\")\n",
    "    print(f\"  Average confidence score: {avg_confidence:.2f}\")\n",
    "    print(f\"  Total entities extracted: {total_entities}\")\n",
    "    print(f\"  Average entities per newsletter: {avg_entities_per_newsletter:.1f}\")\n",
    "    \n",
    "    # Entity quality assessment\n",
    "    high_confidence_entities = sum([len([p for p in result['claude_results'].get('people', []) \n",
    "                                        if p.get('confidence', 0) >= 0.8]) \n",
    "                                   for result in successful_results])\n",
    "    \n",
    "    print(f\"\\n🎯 Quality Metrics:\")\n",
    "    print(f\"  High confidence entities (≥0.8): {high_confidence_entities}/{total_entities} ({high_confidence_entities/max(total_entities, 1)*100:.1f}%)\")\n",
    "    \n",
    "    # Performance by newsletter type\n",
    "    print(f\"\\n📰 Performance by Newsletter Type:\")\n",
    "    for newsletter_type in df_results['newsletter_type'].unique():\n",
    "        type_results = df_results[df_results['newsletter_type'] == newsletter_type]\n",
    "        avg_entities = type_results['people_total'].mean()\n",
    "        avg_time = type_results['processing_time'].mean()\n",
    "        escalation_rate_type = type_results['escalated'].mean() * 100\n",
    "        print(f\"  {newsletter_type}:\")\n",
    "        print(f\"    Average entities: {avg_entities:.1f}\")\n",
    "        print(f\"    Average time: {avg_time:.1f}s\")\n",
    "        print(f\"    Escalation rate: {escalation_rate_type:.1f}%\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n💡 Optimization Recommendations:\")\n",
    "    \n",
    "    if escalation_rate > 30:\n",
    "        print(f\"  ⚡ High escalation rate ({escalation_rate:.1f}%) - consider tuning confidence thresholds\")\n",
    "    elif escalation_rate < 10:\n",
    "        print(f\"  🎯 Low escalation rate ({escalation_rate:.1f}%) - may miss complex relationships\")\n",
    "    else:\n",
    "        print(f\"  ✅ Optimal escalation rate ({escalation_rate:.1f}%)\")\n",
    "    \n",
    "    if avg_processing_time > 10:\n",
    "        print(f\"  ⏰ High processing time ({avg_processing_time:.1f}s) - consider batch processing optimizations\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good processing speed ({avg_processing_time:.1f}s average)\")\n",
    "    \n",
    "    if avg_confidence < 0.7:\n",
    "        print(f\"  🔍 Low average confidence ({avg_confidence:.2f}) - review extraction prompts\")\n",
    "    else:\n",
    "        print(f\"  ✅ High confidence extractions ({avg_confidence:.2f} average)\")\n",
    "        \n",
    "    print(f\"\\n📈 Next Steps:\")\n",
    "    print(f\"  1. Scale testing to full newsletter dataset\")\n",
    "    print(f\"  2. Implement batch processing for efficiency\")\n",
    "    print(f\"  3. Add specialized extraction for newsletter-specific content\")\n",
    "    print(f\"  4. Create entity tracking across multiple newsletters\")\n",
    "    print(f\"  5. Integrate with political intelligence database\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No successful results to assess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive test results for later analysis\n",
    "test_summary = {\n",
    "    'test_date': datetime.now().isoformat(),\n",
    "    'newsletters_tested': len(test_newsletters),\n",
    "    'successful_processing': len(successful_results),\n",
    "    'failed_processing': len(processing_results) - len(successful_results),\n",
    "    'processing_results': processing_results,\n",
    "    'performance_summary': {\n",
    "        'avg_processing_time': df_results['processing_time'].mean() if successful_results else 0,\n",
    "        'escalation_rate': df_results['escalated'].mean() if successful_results else 0,\n",
    "        'avg_confidence': df_results['confidence_score'].mean() if successful_results else 0,\n",
    "        'total_entities': df_results['people_total'].sum() if successful_results else 0\n",
    "    } if successful_results else {}\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "test_results_file = OUTPUT_DIR / f\"claude_nlp_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(test_results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"💾 Test results saved to: {test_results_file}\")\n",
    "print(f\"📁 Enhanced newsletters saved in: {OUTPUT_DIR}\")\n",
    "print(f\"✅ Testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the Claude NLP processor's capabilities across different Politico newsletter types. The system successfully:\n",
    "\n",
    "1. **Extracts comprehensive political intelligence** from various newsletter formats\n",
    "2. **Adapts processing** based on content complexity using two-tier architecture\n",
    "3. **Maintains high accuracy** while optimizing for cost and speed\n",
    "4. **Provides structured output** suitable for further analysis and database integration\n",
    "\n",
    "The processor shows strong performance across different playbook types, with the ability to identify political officials, journalists, staff, and their relationships with high confidence scores.\n",
    "\n",
    "For production deployment, consider:\n",
    "- Batch processing for efficiency\n",
    "- Entity deduplication across newsletters\n",
    "- Integration with political intelligence databases\n",
    "- Real-time processing for live newsletter feeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
