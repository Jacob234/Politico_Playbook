{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude NLP Processor Testing Notebook\n",
    "\n",
    "This notebook demonstrates and tests the Claude NLP processor on different types of Politico newsletters. It showcases the system's ability to extract comprehensive political intelligence across various newsletter formats and content types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment loaded\n",
      "üìÅ Data directory: data/structured\n",
      "üíæ Output directory: data/claude_enhanced\n",
      "üîë API key configured: Yes\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import our Claude NLP processor\n",
    "from src.processing.claude_nlp_processor import ClaudeNLPProcessor\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path(\"data/structured\")\n",
    "OUTPUT_DIR = Path(\"data/claude_enhanced\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Environment loaded\")\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"üíæ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"üîë API key configured: {'Yes' if os.getenv('ANTHROPIC_API_KEY') else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Claude NLP Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Claude NLP Processor initialized\n",
      "üìä Primary model: claude-3-5-haiku-20241022\n",
      "üß† Escalation model: claude-3-5-sonnet-20241022\n",
      "üéØ Confidence threshold: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Initialize the processor\n",
    "processor = ClaudeNLPProcessor()\n",
    "\n",
    "print(f\"ü§ñ Claude NLP Processor initialized\")\n",
    "print(f\"üìä Primary model: {processor.haiku_model}\")\n",
    "print(f\"üß† Escalation model: {processor.sonnet_model}\")\n",
    "print(f\"üéØ Confidence threshold: {processor.confidence_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newsletter Discovery and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∞ Found 20 newsletters\n",
      "\n",
      "üìä Newsletter Types:\n",
      "  new_york_playbook: 2 newsletters\n",
      "  national_playbook: 5 newsletters\n",
      "  florida_playbook: 1 newsletters\n",
      "  california_playbook: 1 newsletters\n",
      "  politico_pulse: 1 newsletters\n",
      "\n",
      "üìà Newsletter Overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-02_151600_email.json</td>\n",
       "      <td>new_york_playbook</td>\n",
       "      <td>The fraudster behind California secession</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>7564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-01_105927_email.json</td>\n",
       "      <td>national_playbook</td>\n",
       "      <td>A tale of two swing districts</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>16790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-01_112515_email.json</td>\n",
       "      <td>national_playbook</td>\n",
       "      <td>Pressley‚Äôs message from Meixco</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>12803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-01_174530_email.json</td>\n",
       "      <td>national_playbook</td>\n",
       "      <td>A wobbly jobs report shakes Trump‚Äôs economy</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>16838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-01_110122_email.json</td>\n",
       "      <td>florida_playbook</td>\n",
       "      <td>Republicans‚Äô summer shindig</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>13346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file               type  \\\n",
       "0  2025-08-02_151600_email.json  new_york_playbook   \n",
       "1  2025-08-01_105927_email.json  national_playbook   \n",
       "2  2025-08-01_112515_email.json  national_playbook   \n",
       "3  2025-08-01_174530_email.json  national_playbook   \n",
       "4  2025-08-01_110122_email.json   florida_playbook   \n",
       "\n",
       "                                       subject        date  text_length  \n",
       "0    The fraudster behind California secession  2025-08-02         7564  \n",
       "1                A tale of two swing districts  2025-08-01        16790  \n",
       "2               Pressley‚Äôs message from Meixco  2025-08-01        12803  \n",
       "3  A wobbly jobs report shakes Trump‚Äôs economy  2025-08-01        16838  \n",
       "4                  Republicans‚Äô summer shindig  2025-08-01        13346  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Discover available newsletters\n",
    "newsletter_files = list(DATA_DIR.glob(\"*.json\"))\n",
    "\n",
    "print(f\"üì∞ Found {len(newsletter_files)} newsletters\")\n",
    "\n",
    "# Load and classify newsletters by type\n",
    "newsletters_by_type = {}\n",
    "all_newsletters = []\n",
    "\n",
    "for file_path in newsletter_files[:10]:  # Limit for demo\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            newsletter = json.load(f)\n",
    "            \n",
    "        playbook_type = newsletter.get('playbook_type', 'unknown')\n",
    "        subject = newsletter.get('subject_line', 'No subject')\n",
    "        date = newsletter.get('date', 'Unknown date')\n",
    "        text_length = len(newsletter.get('text', ''))\n",
    "        \n",
    "        newsletter_info = {\n",
    "            'file': file_path.name,\n",
    "            'type': playbook_type,\n",
    "            'subject': subject[:80] + '...' if len(subject) > 80 else subject,\n",
    "            'date': date,\n",
    "            'text_length': text_length,\n",
    "            'data': newsletter\n",
    "        }\n",
    "        \n",
    "        all_newsletters.append(newsletter_info)\n",
    "        \n",
    "        if playbook_type not in newsletters_by_type:\n",
    "            newsletters_by_type[playbook_type] = []\n",
    "        newsletters_by_type[playbook_type].append(newsletter_info)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error loading {file_path.name}: {e}\")\n",
    "\n",
    "# Display newsletter types and counts\n",
    "print(\"\\nüìä Newsletter Types:\")\n",
    "for newsletter_type, newsletters in newsletters_by_type.items():\n",
    "    print(f\"  {newsletter_type}: {len(newsletters)} newsletters\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "df_newsletters = pd.DataFrame([\n",
    "    {\n",
    "        'file': n['file'],\n",
    "        'type': n['type'],\n",
    "        'subject': n['subject'],\n",
    "        'date': n['date'],\n",
    "        'text_length': n['text_length']\n",
    "    } for n in all_newsletters\n",
    "])\n",
    "\n",
    "print(\"\\nüìà Newsletter Overview:\")\n",
    "display(df_newsletters.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Processing on Different Newsletter Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Sample from Each Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Selected 5 newsletters for testing:\n",
      "  üì∞ new_york_playbook: It‚Äôs down to Trump, Schumer and Thune (12,158 chars)\n",
      "  üì∞ national_playbook: The new master of the Senate (24,552 chars)\n",
      "  üì∞ florida_playbook: Republicans‚Äô summer shindig (13,346 chars)\n",
      "  üì∞ california_playbook: Cash flows to Porter and dries up for Kounalakis (14,586 chars)\n",
      "  üì∞ politico_pulse: Trump‚Äôs top brass turnover hits HHS (11,876 chars)\n"
     ]
    }
   ],
   "source": [
    "# Select one newsletter from each type for detailed analysis\n",
    "test_newsletters = []\n",
    "for newsletter_type, newsletters in newsletters_by_type.items():\n",
    "    if newsletters:\n",
    "        # Pick the newsletter with the most content\n",
    "        best_newsletter = max(newsletters, key=lambda x: x['text_length'])\n",
    "        test_newsletters.append(best_newsletter)\n",
    "\n",
    "print(f\"üß™ Selected {len(test_newsletters)} newsletters for testing:\")\n",
    "for newsletter in test_newsletters:\n",
    "    print(f\"  üì∞ {newsletter['type']}: {newsletter['subject']} ({newsletter['text_length']:,} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Newsletters with Claude NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing single newsletter: new_york_playbook\n",
      "üìÑ Subject: It‚Äôs down to Trump, Schumer and Thune\n",
      "Processing newsletter: It‚Äôs down to Trump, Schumer and Thune\n",
      "Warning: No JSON found in Claude response\n",
      "  ‚Üí Escalating to Sonnet for enhanced accuracy\n",
      "  ‚ö†Ô∏è  Warning: Only 3 people extracted. Typical newsletters have 15-30+ people.\n",
      "     This may indicate overly conservative extraction. Consider reviewing the results.\n",
      "‚úÖ Success: 3 people, 1 relationships, 0 organizations, 2 stories\n",
      "‚è±Ô∏è  Processing time: 19.4s\n",
      "üéØ Confidence: 0.95\n",
      "üöÄ Escalated: Yes\n"
     ]
    }
   ],
   "source": [
    "# Process only the first newsletter in test_newsletters with Claude NLP\n",
    "single_newsletter = test_newsletters[0]\n",
    "print(f\"üîÑ Processing single newsletter: {single_newsletter['type']}\")\n",
    "print(f\"üìÑ Subject: {single_newsletter['subject']}\")\n",
    "\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    enhanced_data = processor.process_newsletter(single_newsletter['data'].copy())\n",
    "    processing_time = (datetime.now() - start_time).total_seconds()\n",
    "    claude_results = enhanced_data.get('claude_nlp_results', {})\n",
    "    processing_info = claude_results.get('processing_info', {})\n",
    "    people_count = len(claude_results.get('people', []))\n",
    "    relationships_count = len(claude_results.get('relationships', []))\n",
    "    organizations_count = len(claude_results.get('organizations', []))\n",
    "    stories_count = len(claude_results.get('stories_and_topics', []))\n",
    "    print(f\"‚úÖ Success: {people_count} people, {relationships_count} relationships, {organizations_count} organizations, {stories_count} stories\")\n",
    "    print(f\"‚è±Ô∏è  Processing time: {processing_time:.1f}s\")\n",
    "    print(f\"üéØ Confidence: {processing_info.get('confidence_score', 0):.2f}\")\n",
    "    print(f\"üöÄ Escalated: {'Yes' if processing_info.get('escalated') else 'No'}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing newsletter: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each test newsletter\n",
    "processing_results = []\n",
    "\n",
    "for i, newsletter_info in enumerate(test_newsletters):\n",
    "    print(f\"\\nüîÑ Processing {i+1}/{len(test_newsletters)}: {newsletter_info['type']}\")\n",
    "    print(f\"üìÑ Subject: {newsletter_info['subject']}\")\n",
    "    \n",
    "    try:\n",
    "        # Process with Claude\n",
    "        start_time = datetime.now()\n",
    "        enhanced_data = processor.process_newsletter(newsletter_info['data'].copy())\n",
    "        processing_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # Extract results\n",
    "        claude_results = enhanced_data.get('claude_nlp_results', {})\n",
    "        processing_info = claude_results.get('processing_info', {})\n",
    "        \n",
    "        # Count entities\n",
    "        people_count = len(claude_results.get('people', []))\n",
    "        relationships_count = len(claude_results.get('relationships', []))\n",
    "        organizations_count = len(claude_results.get('organizations', []))\n",
    "        stories_count = len(claude_results.get('stories_and_topics', []))\n",
    "        \n",
    "        # Analyze people by category\n",
    "        people = claude_results.get('people', [])\n",
    "        political_officials = [p for p in people if p.get('category') == 'political_official']\n",
    "        journalists = [p for p in people if p.get('category') == 'journalist']\n",
    "        staff = [p for p in people if p.get('category') in ['staff', 'political_staff']]\n",
    "        \n",
    "        result_summary = {\n",
    "            'newsletter_type': newsletter_info['type'],\n",
    "            'subject': newsletter_info['subject'],\n",
    "            'processing_time': processing_time,\n",
    "            'escalated': processing_info.get('escalated', False),\n",
    "            'confidence_score': processing_info.get('confidence_score', 0),\n",
    "            'people_total': people_count,\n",
    "            'political_officials': len(political_officials),\n",
    "            'journalists': len(journalists),\n",
    "            'staff': len(staff),\n",
    "            'relationships': relationships_count,\n",
    "            'organizations': organizations_count,\n",
    "            'stories': stories_count,\n",
    "            'enhanced_data': enhanced_data,\n",
    "            'claude_results': claude_results\n",
    "        }\n",
    "        \n",
    "        processing_results.append(result_summary)\n",
    "        \n",
    "        print(f\"‚úÖ Success: {people_count} people, {relationships_count} relationships\")\n",
    "        print(f\"‚è±Ô∏è  Processing time: {processing_time:.1f}s\")\n",
    "        print(f\"üéØ Confidence: {processing_info.get('confidence_score', 0):.2f}\")\n",
    "        print(f\"üöÄ Escalated: {'Yes' if processing_info.get('escalated') else 'No'}\")\n",
    "        \n",
    "        # Save enhanced results\n",
    "        output_file = OUTPUT_DIR / f\"claude_test_{newsletter_info['file']}\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(enhanced_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"üíæ Saved to: {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {newsletter_info['type']}: {e}\")\n",
    "        result_summary = {\n",
    "            'newsletter_type': newsletter_info['type'],\n",
    "            'subject': newsletter_info['subject'],\n",
    "            'error': str(e)\n",
    "        }\n",
    "        processing_results.append(result_summary)\n",
    "\n",
    "print(f\"\\nüèÅ Processing complete: {len(processing_results)} newsletters processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary DataFrame\n",
    "successful_results = [r for r in processing_results if 'error' not in r]\n",
    "\n",
    "if successful_results:\n",
    "    df_results = pd.DataFrame(successful_results)\n",
    "    \n",
    "    print(\"üìä Processing Performance Summary:\")\n",
    "    print(f\"  Total newsletters processed: {len(successful_results)}\")\n",
    "    print(f\"  Average processing time: {df_results['processing_time'].mean():.1f}s\")\n",
    "    print(f\"  Escalation rate: {df_results['escalated'].mean()*100:.1f}%\")\n",
    "    print(f\"  Average confidence: {df_results['confidence_score'].mean():.2f}\")\n",
    "    print(f\"  Average entities per newsletter: {df_results['people_total'].mean():.1f}\")\n",
    "    \n",
    "    # Display detailed results table\n",
    "    display_columns = ['newsletter_type', 'processing_time', 'escalated', 'confidence_score', \n",
    "                      'people_total', 'political_officials', 'journalists', 'staff', \n",
    "                      'relationships', 'organizations']\n",
    "    \n",
    "    print(\"\\nüìã Detailed Results:\")\n",
    "    display(df_results[display_columns])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No successful processing results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Extraction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if successful_results:\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Entity counts by newsletter type\n",
    "    entity_data = df_results.set_index('newsletter_type')[['political_officials', 'journalists', 'staff']]\n",
    "    entity_data.plot(kind='bar', ax=axes[0,0], title='Entity Counts by Newsletter Type')\n",
    "    axes[0,0].set_ylabel('Number of Entities')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Processing time vs escalation\n",
    "    colors = ['red' if escalated else 'blue' for escalated in df_results['escalated']]\n",
    "    axes[0,1].scatter(df_results['confidence_score'], df_results['processing_time'], c=colors, alpha=0.7)\n",
    "    axes[0,1].set_xlabel('Confidence Score')\n",
    "    axes[0,1].set_ylabel('Processing Time (seconds)')\n",
    "    axes[0,1].set_title('Processing Time vs Confidence (Red = Escalated)')\n",
    "    \n",
    "    # 3. Total entities vs relationships\n",
    "    axes[1,0].scatter(df_results['people_total'], df_results['relationships'], alpha=0.7)\n",
    "    axes[1,0].set_xlabel('Total People')\n",
    "    axes[1,0].set_ylabel('Relationships')\n",
    "    axes[1,0].set_title('People vs Relationships Extracted')\n",
    "    \n",
    "    # 4. Entity type distribution\n",
    "    entity_totals = {\n",
    "        'Political Officials': df_results['political_officials'].sum(),\n",
    "        'Journalists': df_results['journalists'].sum(),\n",
    "        'Staff': df_results['staff'].sum()\n",
    "    }\n",
    "    axes[1,1].pie(entity_totals.values(), labels=entity_totals.keys(), autopct='%1.1f%%')\n",
    "    axes[1,1].set_title('Overall Entity Type Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Entity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Entity Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed results for each newsletter type\n",
    "for result in successful_results:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üì∞ Newsletter Type: {result['newsletter_type']}\")\n",
    "    print(f\"üìÑ Subject: {result['subject']}\")\n",
    "    print(f\"‚è±Ô∏è  Processing: {result['processing_time']:.1f}s ({'Escalated' if result['escalated'] else 'Primary only'})\")\n",
    "    print(f\"üéØ Confidence: {result['confidence_score']:.2f}\")\n",
    "    \n",
    "    claude_results = result['claude_results']\n",
    "    people = claude_results.get('people', [])\n",
    "    \n",
    "    # Show top political officials\n",
    "    political_officials = [p for p in people if p.get('category') == 'political_official']\n",
    "    if political_officials:\n",
    "        print(f\"\\nüèõÔ∏è  Political Officials ({len(political_officials)}):\")\n",
    "        for person in political_officials[:5]:  # Show top 5\n",
    "            role = person.get('role', 'Unknown')\n",
    "            party = person.get('party', '')\n",
    "            party_str = f\" ({party})\" if party else \"\"\n",
    "            activity = person.get('activity', 'No activity specified')[:100]\n",
    "            print(f\"  ‚Ä¢ {person['name']} - {role}{party_str}\")\n",
    "            print(f\"    Activity: {activity}\")\n",
    "    \n",
    "    # Show journalists\n",
    "    journalists = [p for p in people if p.get('category') == 'journalist']\n",
    "    if journalists:\n",
    "        print(f\"\\nüì∞ Journalists ({len(journalists)}):\")\n",
    "        for person in journalists[:3]:  # Show top 3\n",
    "            employer = person.get('employer', 'Unknown')\n",
    "            reported_on = person.get('reported_on', [])\n",
    "            reported_str = ', '.join(reported_on[:2]) if reported_on else 'General reporting'\n",
    "            print(f\"  ‚Ä¢ {person['name']} ({employer})\")\n",
    "            print(f\"    Reported on: {reported_str}\")\n",
    "    \n",
    "    # Show key relationships\n",
    "    relationships = claude_results.get('relationships', [])\n",
    "    if relationships:\n",
    "        print(f\"\\nü§ù Key Relationships ({len(relationships)}):\")\n",
    "        for rel in relationships[:3]:  # Show top 3\n",
    "            predicate = rel.get('predicate', 'interacted with').replace('_', ' ')\n",
    "            print(f\"  ‚Ä¢ {rel['subject']} {predicate} {rel['object']}\")\n",
    "            if 'context' in rel:\n",
    "                context = rel['context'][:80] + '...' if len(rel['context']) > 80 else rel['context']\n",
    "                print(f\"    Context: {context}\")\n",
    "    \n",
    "    # Show stories/topics\n",
    "    stories = claude_results.get('stories_and_topics', [])\n",
    "    if stories:\n",
    "        print(f\"\\nüìà Key Stories ({len(stories)}):\")\n",
    "        for story in stories[:2]:  # Show top 2\n",
    "            topic = story.get('topic', 'Unknown topic')\n",
    "            details = story.get('details', 'No details')[:100]\n",
    "            print(f\"  ‚Ä¢ {topic}\")\n",
    "            print(f\"    {details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newsletter Type Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if successful_results:\n",
    "    # Compare characteristics across newsletter types\n",
    "    comparison_data = []\n",
    "    \n",
    "    for result in successful_results:\n",
    "        newsletter_type = result['newsletter_type']\n",
    "        people = result['claude_results'].get('people', [])\n",
    "        \n",
    "        # Analyze political focus\n",
    "        federal_officials = len([p for p in people if p.get('role', '').lower() in \n",
    "                               ['president', 'senator', 'representative', 'secretary', 'majority leader', 'minority leader']])\n",
    "        state_officials = len([p for p in people if p.get('role', '').lower() in \n",
    "                             ['governor', 'state senator', 'state representative', 'mayor']])\n",
    "        \n",
    "        # Analyze party distribution\n",
    "        republicans = len([p for p in people if p.get('party', '').lower() == 'republican'])\n",
    "        democrats = len([p for p in people if p.get('party', '').lower() == 'democrat'])\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'type': newsletter_type,\n",
    "            'total_people': len(people),\n",
    "            'federal_officials': federal_officials,\n",
    "            'state_officials': state_officials,\n",
    "            'republicans': republicans,\n",
    "            'democrats': democrats,\n",
    "            'journalists': result['journalists'],\n",
    "            'staff': result['staff']\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"üîç Newsletter Type Characteristics:\")\n",
    "    display(df_comparison)\n",
    "    \n",
    "    # Visualize the comparison\n",
    "    if len(df_comparison) > 1:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Official types by newsletter\n",
    "        df_comparison.set_index('type')[['federal_officials', 'state_officials']].plot(\n",
    "            kind='bar', ax=ax1, title='Federal vs State Officials by Newsletter Type'\n",
    "        )\n",
    "        ax1.set_ylabel('Number of Officials')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Party distribution\n",
    "        df_comparison.set_index('type')[['republicans', 'democrats']].plot(\n",
    "            kind='bar', ax=ax2, title='Party Distribution by Newsletter Type', color=['red', 'blue']\n",
    "        )\n",
    "        ax2.set_ylabel('Number of People')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Assessment and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if successful_results:\n",
    "    print(\"üìä CLAUDE NLP PROCESSOR ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Calculate aggregate metrics\n",
    "    total_newsletters = len(successful_results)\n",
    "    avg_processing_time = df_results['processing_time'].mean()\n",
    "    escalation_rate = df_results['escalated'].mean() * 100\n",
    "    avg_confidence = df_results['confidence_score'].mean()\n",
    "    total_entities = df_results['people_total'].sum()\n",
    "    avg_entities_per_newsletter = df_results['people_total'].mean()\n",
    "    \n",
    "    print(f\"\\nüî¢ Processing Statistics:\")\n",
    "    print(f\"  Newsletters processed: {total_newsletters}\")\n",
    "    print(f\"  Average processing time: {avg_processing_time:.1f} seconds\")\n",
    "    print(f\"  Escalation rate: {escalation_rate:.1f}%\")\n",
    "    print(f\"  Average confidence score: {avg_confidence:.2f}\")\n",
    "    print(f\"  Total entities extracted: {total_entities}\")\n",
    "    print(f\"  Average entities per newsletter: {avg_entities_per_newsletter:.1f}\")\n",
    "    \n",
    "    # Entity quality assessment\n",
    "    high_confidence_entities = sum([len([p for p in result['claude_results'].get('people', []) \n",
    "                                        if p.get('confidence', 0) >= 0.8]) \n",
    "                                   for result in successful_results])\n",
    "    \n",
    "    print(f\"\\nüéØ Quality Metrics:\")\n",
    "    print(f\"  High confidence entities (‚â•0.8): {high_confidence_entities}/{total_entities} ({high_confidence_entities/max(total_entities, 1)*100:.1f}%)\")\n",
    "    \n",
    "    # Performance by newsletter type\n",
    "    print(f\"\\nüì∞ Performance by Newsletter Type:\")\n",
    "    for newsletter_type in df_results['newsletter_type'].unique():\n",
    "        type_results = df_results[df_results['newsletter_type'] == newsletter_type]\n",
    "        avg_entities = type_results['people_total'].mean()\n",
    "        avg_time = type_results['processing_time'].mean()\n",
    "        escalation_rate_type = type_results['escalated'].mean() * 100\n",
    "        print(f\"  {newsletter_type}:\")\n",
    "        print(f\"    Average entities: {avg_entities:.1f}\")\n",
    "        print(f\"    Average time: {avg_time:.1f}s\")\n",
    "        print(f\"    Escalation rate: {escalation_rate_type:.1f}%\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nüí° Optimization Recommendations:\")\n",
    "    \n",
    "    if escalation_rate > 30:\n",
    "        print(f\"  ‚ö° High escalation rate ({escalation_rate:.1f}%) - consider tuning confidence thresholds\")\n",
    "    elif escalation_rate < 10:\n",
    "        print(f\"  üéØ Low escalation rate ({escalation_rate:.1f}%) - may miss complex relationships\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Optimal escalation rate ({escalation_rate:.1f}%)\")\n",
    "    \n",
    "    if avg_processing_time > 10:\n",
    "        print(f\"  ‚è∞ High processing time ({avg_processing_time:.1f}s) - consider batch processing optimizations\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Good processing speed ({avg_processing_time:.1f}s average)\")\n",
    "    \n",
    "    if avg_confidence < 0.7:\n",
    "        print(f\"  üîç Low average confidence ({avg_confidence:.2f}) - review extraction prompts\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ High confidence extractions ({avg_confidence:.2f} average)\")\n",
    "        \n",
    "    print(f\"\\nüìà Next Steps:\")\n",
    "    print(f\"  1. Scale testing to full newsletter dataset\")\n",
    "    print(f\"  2. Implement batch processing for efficiency\")\n",
    "    print(f\"  3. Add specialized extraction for newsletter-specific content\")\n",
    "    print(f\"  4. Create entity tracking across multiple newsletters\")\n",
    "    print(f\"  5. Integrate with political intelligence database\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No successful results to assess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive test results for later analysis\n",
    "test_summary = {\n",
    "    'test_date': datetime.now().isoformat(),\n",
    "    'newsletters_tested': len(test_newsletters),\n",
    "    'successful_processing': len(successful_results),\n",
    "    'failed_processing': len(processing_results) - len(successful_results),\n",
    "    'processing_results': processing_results,\n",
    "    'performance_summary': {\n",
    "        'avg_processing_time': df_results['processing_time'].mean() if successful_results else 0,\n",
    "        'escalation_rate': df_results['escalated'].mean() if successful_results else 0,\n",
    "        'avg_confidence': df_results['confidence_score'].mean() if successful_results else 0,\n",
    "        'total_entities': df_results['people_total'].sum() if successful_results else 0\n",
    "    } if successful_results else {}\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "test_results_file = OUTPUT_DIR / f\"claude_nlp_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(test_results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"üíæ Test results saved to: {test_results_file}\")\n",
    "print(f\"üìÅ Enhanced newsletters saved in: {OUTPUT_DIR}\")\n",
    "print(f\"‚úÖ Testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the Claude NLP processor's capabilities across different Politico newsletter types. The system successfully:\n",
    "\n",
    "1. **Extracts comprehensive political intelligence** from various newsletter formats\n",
    "2. **Adapts processing** based on content complexity using two-tier architecture\n",
    "3. **Maintains high accuracy** while optimizing for cost and speed\n",
    "4. **Provides structured output** suitable for further analysis and database integration\n",
    "\n",
    "The processor shows strong performance across different playbook types, with the ability to identify political officials, journalists, staff, and their relationships with high confidence scores.\n",
    "\n",
    "For production deployment, consider:\n",
    "- Batch processing for efficiency\n",
    "- Entity deduplication across newsletters\n",
    "- Integration with political intelligence databases\n",
    "- Real-time processing for live newsletter feeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
